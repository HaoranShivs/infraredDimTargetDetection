{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import yaml\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from net.basenet import GaussNet3, GaussianConv2d\n",
    "from dataprocess.sirst import NUDTDataset, IRSTD1kDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_size = 128\n",
    "pict = np.array(cv2.resize(cv2.imread('W:/DataSets/ISTD/IRSTD-1k/trainval/masks/XDU116.png', 0), [base_size, base_size], interpolation=cv2.INTER_LINEAR))\n",
    "pict = np.array((pict, np.array(cv2.resize(cv2.imread('W:/DataSets/ISTD/IRSTD-1k/trainval/images/XDU116.png', 0), [base_size, base_size], interpolation=cv2.INTER_LINEAR))))\n",
    "# pict = cv2.resize(pict, [2, 256, 256], interpolation=cv2.INTER_LINEAR)\n",
    "pict = torch.from_numpy(pict).type(torch.float32)/255\n",
    "# pict = pict.unsqueeze(0).view(2, 1, 240, 320)\n",
    "# pict = pict[:,:,:,:240]\n",
    "# pict = pict[:,:,:240]\n",
    "print(pict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GaussianConv2d(1, 3, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = net(pict[1:2,])\n",
    "\n",
    "print(net.atten.weight.data)\n",
    "print(net.tempreture)\n",
    "print(net.bias)\n",
    "\n",
    "originp = np.array(pict)\n",
    "# originp = (originp * 255).astype(np.uint8)\n",
    "gaussp = res.detach().numpy()\n",
    "gaussp = (gaussp - np.min(gaussp)) / (np.max(gaussp)-np.min(gaussp))\n",
    "# gaussp = (gaussp * 255).astype(np.uint8)\n",
    "\n",
    "# # 转换为PIL图像\n",
    "# pil_image = Image.fromarray(gaussp[0, 0])\n",
    "\n",
    "# # 保存图像\n",
    "# pil_image.save(\"output4.png\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "# plt.imshow(gaussp[0,0], cmap='gray')\n",
    "axes[0].imshow(gaussp[0, 0], cmap='gray')\n",
    "axes[0].axis('off')  # 关闭坐标轴显示\n",
    "    \n",
    "axes[1].imshow(originp[1], cmap='gray')\n",
    "axes[1].axis('off')  # 同样关闭坐标轴显示\n",
    "# plt.title('Blurred Image')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def gaussian_kernel(channel, kernel_size, sigma):\n",
    "    \"\"\"创建一个高斯核\"\"\"\n",
    "    # 创建一个一维高斯核\n",
    "    kernel_1d = torch.Tensor([math.exp(-z ** 2.0 / (2 * sigma ** 2)) for z in range(-kernel_size // 2 + 1, kernel_size // 2 + 1)])\n",
    "    # 将一维高斯核扩展为二维\n",
    "    kernel_2d = torch.outer(kernel_1d, kernel_1d)\n",
    "    # 归一化\n",
    "    kernel_2d /= kernel_2d.sum()\n",
    "    kernel_2d[kernel_size // 2, kernel_size // 2] = -kernel_2d[kernel_size // 2, kernel_size // 2]\n",
    "    # 整个卷积核参数\n",
    "    params = torch.zeros((channel, channel, kernel_size, kernel_size))\n",
    "    for i in range(channel):\n",
    "        params[i, i] = kernel_2d\n",
    "    return params\n",
    "\n",
    "res = gaussian_kernel(1,3,0.6)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_path = \"result/20240819T08-38-33_new_gauss2_1_irstd1k/best.pkl\"\n",
    "params = torch.load(pt_path)\n",
    "# for key in params:\n",
    "#     print(key)\n",
    "for k in params:\n",
    "    if \"gauss.bias\" in k:\n",
    "        print(k)\n",
    "        print(params[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = 'cfg.yaml'\n",
    "with open(cfg_path) as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "net = GaussNet3(1, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "augment = transforms.Compose([\n",
    "                    transforms.RandomAffine(degrees=180, translate=(0.1, 0.1), shear=0),\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(cv2.imread(\"result/20240812T12-46-54_gauss9_1_irstd1k/nudt_result.png\", 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "sigma = 2\n",
    "kernel_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gauss_kernel():\n",
    "    kernel_size = 3\n",
    "    sigma = 2\n",
    "\n",
    "    kernels = []\n",
    "    for i in range(kernel_size):\n",
    "        for j in range(kernel_size):\n",
    "            x = torch.arange(0, kernel_size, 1, dtype=torch.float32) - i\n",
    "            y = torch.arange(0, kernel_size, 1, dtype=torch.float32) - j\n",
    "            kernel_1d_x = torch.exp(-(x**2) / (2 * sigma**2))\n",
    "            kernel_1d_y = torch.exp(-(y**2) / (2 * sigma**2))\n",
    "            kernel_2d = torch.outer(kernel_1d_x, kernel_1d_y)\n",
    "            # 归一化\n",
    "            kernel_2d /= kernel_2d.sum()\n",
    "            kernels.append(kernel_2d)\n",
    "\n",
    "    return kernels\n",
    "\n",
    "result = generate_gauss_kernel()\n",
    "for i in result:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 48, 64, 96, 128]\n"
     ]
    }
   ],
   "source": [
    "from dataprocess.croped_sirst import Crop_IRSTD1kDataset\n",
    "import yaml\n",
    "import torch\n",
    "\n",
    "cfg_path = 'cfg.yaml'\n",
    "with open(cfg_path) as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "print(cfg[\"multiscalefeature_outchannel\"])\n",
    "\n",
    "dataset = Crop_IRSTD1kDataset(base_dir=r\"W:/DataSets/ISTD/IRSTD-1k\", mode=\"train\", base_size=32)\n",
    "# train_data_loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 16])\n",
      "torch.Size([2, 32, 32])\n",
      "torch.Size([32, 32])\n",
      "tensor([ 7, 13])\n",
      "torch.Size([2, 16, 16])\n",
      "torch.Size([2, 32, 32])\n",
      "torch.Size([32, 32])\n",
      "tensor([10,  3])\n",
      "torch.Size([2, 8, 8])\n",
      "torch.Size([2, 32, 32])\n",
      "torch.Size([32, 32])\n",
      "tensor([19, 14])\n",
      "torch.Size([2, 16, 16])\n",
      "torch.Size([2, 32, 32])\n",
      "torch.Size([32, 32])\n",
      "tensor([10, 12])\n",
      "torch.Size([2, 16, 16])\n",
      "torch.Size([2, 32, 32])\n",
      "torch.Size([32, 32])\n",
      "tensor([7, 7])\n",
      "torch.Size([2, 16, 16])\n",
      "torch.Size([2, 32, 32])\n",
      "torch.Size([32, 32])\n",
      "tensor([0, 6])\n",
      "torch.Size([2, 16, 16])\n",
      "torch.Size([2, 32, 32])\n",
      "torch.Size([32, 32])\n",
      "tensor([9, 8])\n",
      "torch.Size([2, 16, 16])\n",
      "torch.Size([2, 32, 32])\n",
      "torch.Size([32, 32])\n",
      "tensor([10,  2])\n",
      "torch.Size([2, 16, 16])\n",
      "torch.Size([2, 32, 32])\n",
      "torch.Size([32, 32])\n",
      "tensor([6, 5])\n"
     ]
    }
   ],
   "source": [
    "i = 8\n",
    "labels = []\n",
    "datas = []\n",
    "for data, label in dataset:\n",
    "    i -= 1\n",
    "    if i < 0:\n",
    "        break\n",
    "    labels.append(label.squeeze())\n",
    "    datas.append(data.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label = np.array(labels)\n",
    "datas = np.array(datas)\n",
    "print(datas.shape)\n",
    "# originp = (originp * 255).astype(np.uint8)\n",
    "# gaussp = res.detach().numpy()\n",
    "# gaussp = (gaussp - np.min(gaussp)) / (np.max(gaussp)-np.min(gaussp))\n",
    "# gaussp = (gaussp * 255).astype(np.uint8)\n",
    "\n",
    "# # 转换为PIL图像\n",
    "# pil_image = Image.fromarray(gaussp[0, 0])\n",
    "\n",
    "# # 保存图像\n",
    "# pil_image.save(\"output4.png\")\n",
    "row_num = label.shape[0]\n",
    "fig, axes = plt.subplots(row_num, 2)\n",
    "for i in range(row_num):\n",
    "    # plt.imshow(gaussp[0,0], cmap='gray')\n",
    "    axes[i, 0].imshow(label[i], cmap='gray')\n",
    "    axes[i, 0].axis('off')  # 关闭坐标轴显示\n",
    "        \n",
    "    axes[i, 1].imshow(datas[i], cmap='gray')\n",
    "    axes[i, 1].axis('off')  # 同样关闭坐标轴显示\n",
    "    # plt.title('Blurred Image')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multiscale_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from net.twotasknet import Heatmap_net\n",
    "\n",
    "# 1. 准备模型\n",
    "model = Heatmap_net(1, cfg)\n",
    "model.eval()  # 设置模型为评估模式\n",
    "\n",
    "# 2. 定义输入形状\n",
    "dummy_input = torch.randn(32, 1, 256, 256)  # 一个batch_size=1的示例输入\n",
    "\n",
    "# 3. 导出模型 \n",
    "torch.onnx.export(\n",
    "    model,  # 模型实例\n",
    "    dummy_input,  # 示例输入\n",
    "    \"heatmap_net.onnx\",  # 输出文件名\n",
    "    export_params=True,  # 存储模型参数 \n",
    "    opset_version=17,  # ONNX版本\n",
    "    do_constant_folding=True,  # 是否执行常量折叠优化\n",
    "    input_names=['input'],  # 输入节点名称\n",
    "    output_names=['output'],  # 输出节点名称\n",
    "    dynamic_axes={'input': {0: 'batch_size'},  # 可变维度\n",
    "                  'output': {0: 'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from net.twotasknet import HeatMaptoImg\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from net.twotasknet import TwoTaskNetWithLoss\n",
    "from net.attentionnet import attenMultiplyUNet\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "cfg_path = 'cfg.yaml'\n",
    "with open(cfg_path) as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4427350\n"
     ]
    }
   ],
   "source": [
    "net = attenMultiplyUNet(cfg)\n",
    "print(count_parameters(net))\n",
    "# a = count_parameters(net.net_heatmap)\n",
    "# print(a)\n",
    "# b = count_parameters(net.net_localseg)\n",
    "# print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6311],\n",
      "        [ 0.5071]])\n",
      "tensor([[ 0.7653, -0.2173,  1.6988,  0.1399],\n",
      "        [ 0.9701, -0.9867,  0.0586,  1.1327]])\n",
      "tensor([[-0.4830,  0.1371, -1.0721, -0.0883],\n",
      "        [ 0.4919, -0.5003,  0.0297,  0.5743]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn((2,1))\n",
    "print(a)\n",
    "b = torch.randn((2,4))\n",
    "print(b)\n",
    "c = a * b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.2945, -1.6937, -0.4777, -0.8346,  0.0160, -0.3761,  0.6503,\n",
      "            0.4362],\n",
      "          [-0.3471, -0.9358,  0.8630,  0.3979,  0.3385,  0.2603,  0.0579,\n",
      "           -0.6900],\n",
      "          [-0.5948,  0.1526, -1.1665,  0.8847,  0.7445,  0.8429,  0.4279,\n",
      "           -0.3104],\n",
      "          [-1.3352, -0.6949, -0.1322,  1.0315, -0.8240, -0.3998,  0.8544,\n",
      "            0.4026],\n",
      "          [-0.6897,  0.8612, -0.8703,  1.2025,  0.0348, -0.7983,  0.2408,\n",
      "            1.7760],\n",
      "          [ 0.2202,  0.6050,  0.3708, -0.5983, -0.5442, -0.1587,  0.4599,\n",
      "           -0.7493],\n",
      "          [-0.1097,  0.6814, -0.0685,  2.2017,  0.1956, -0.7722,  0.4304,\n",
      "           -0.1054],\n",
      "          [ 1.2892, -1.2722, -0.9184,  0.0404,  0.0147,  0.6385, -0.3078,\n",
      "            0.6058]]],\n",
      "\n",
      "\n",
      "        [[[-1.3255,  0.6792,  0.9170,  1.1509, -1.3670,  0.1873,  0.3723,\n",
      "           -0.7406],\n",
      "          [-0.4857, -0.5493, -0.7397, -2.0155,  0.1307,  0.3393, -0.2101,\n",
      "           -0.0908],\n",
      "          [ 2.2744,  0.5956, -1.2879,  0.9637, -0.7102, -0.3941, -0.6435,\n",
      "           -1.6383],\n",
      "          [-0.6573, -0.6685,  1.0276,  1.2540,  1.2159,  1.1199,  0.5085,\n",
      "            0.8890],\n",
      "          [-1.2655,  1.3690,  0.5648, -0.7747,  0.5581,  0.4251, -0.7615,\n",
      "           -0.4241],\n",
      "          [ 0.2194, -0.5965,  0.7406,  0.5854,  1.1390,  0.6783,  2.3793,\n",
      "           -0.6191],\n",
      "          [-0.5416, -0.9157, -0.4096, -0.2153, -1.1364,  0.3661,  0.0717,\n",
      "            0.2928],\n",
      "          [-0.6223,  0.6734, -0.7893,  0.5754, -0.3061, -0.2323,  0.1121,\n",
      "            0.5260]]]])\n"
     ]
    }
   ],
   "source": [
    "data = torch.randn((2,1,8,8))\n",
    "insert_data = torch.tensor([])\n",
    "\n",
    "data2 = torch.concatenate((data, insert_data), dim=0)\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from net.twotasknet import LocalSegment2\n",
    "\n",
    "net = LocalSegment2(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444705\n"
     ]
    }
   ],
   "source": [
    "print(count_parameters(net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 48, 3, 3]) torch.Size([8, 64, 2, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m input_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m48\u001b[39m,\u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(res\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mw:\\Tools\\conda\\envs\\torch221\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mw:\\Tools\\conda\\envs\\torch221\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mw:\\Projects\\infraredDimTargetDetection\\net\\twotasknet.py:658\u001b[0m, in \u001b[0;36mLocalSegment2.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mprint\u001b[39m(x4\u001b[38;5;241m.\u001b[39mshape,x5\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    657\u001b[0m xT4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeT5(x5)\n\u001b[1;32m--> 658\u001b[0m x4 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxT4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx4\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m x3 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeT4(x4), x3)\n\u001b[0;32m    660\u001b[0m x2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeT3(x3), x2)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "input_data = torch.randn((8,1,32,32))\n",
    "res = net(input_data)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from net.attentionnet import ConvDownSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn((4,1,256,256))\n",
    "\n",
    "net = ConvDownSample(1,1)\n",
    "\n",
    "res = net(a)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch221",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
